{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2EkY1mLubetN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59292722-425c-478d-d637-a73ec7d268be"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GByWdy97ZNbR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas\n",
        "import numpy as np\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j8zPmvwWZNbT"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "#dataset taken from https://www.kaggle.com/yashsawarn/wifi-stretgth-for-rooms\n",
        "    \n",
        "    \n",
        "def read_dataset(csv_name = 'sao-paulo-properties-april-2019.csv'):\n",
        "    \"\"\"\n",
        "    Reads a csv dataset \n",
        "    returns it as a pytorch tensor\n",
        "    \"\"\"\n",
        "    data_frame = pandas.read_csv(csv_name)\n",
        "        \n",
        "    #do data preprocessing and return torch matrix with targets in the last column\n",
        "    \"\"\"\n",
        "    Creates a new column with categories using the \"price\" column\n",
        "      1) 900000 < y , categoría 4\n",
        "      2) 580000 < y < 900000, categoría 3\n",
        "      3) 400000 < y < 580000, categoría 2\n",
        "      4) y < 400000, categoría 1    \n",
        "    \"\"\"\n",
        "    data_frame.loc[ data_frame['Price'] <  400000, 'Class'] = 1\n",
        "    data_frame.loc[(data_frame['Price'] >= 400000) & (data_frame['Price'] < 580000), 'Class'] = 2\n",
        "    data_frame.loc[(data_frame['Price'] >= 580000) & (data_frame['Price'] < 900000), 'Class'] = 3\n",
        "    data_frame.loc[ data_frame['Price'] >= 900000, 'Class'] = 4\n",
        "    data_frame['Class'] = data_frame['Class'].astype('int')\n",
        "    \n",
        "    #Remove all unnecesary attributes and leave only the ones that we need\n",
        "    data_frame = data_frame.loc[:, ['Rooms', 'Size', 'Toilets', 'Parking', 'Class']]\n",
        "    \n",
        "    return data_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f3_6DqEAZNbU",
        "outputId": "0333d0af-2393-4afa-c947-d6a9f9b2d2b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy for depth 2 is of:  0.6438496117695137 \n",
            "\n",
            "The accuracy for depth 3 is of:  0.6442582754393135 \n",
            "\n",
            "************** Testing with partitions **************** \n",
            "\n",
            "Testing with partitions and depth = 2 \n",
            "\n",
            "   Accuracy of partition\n",
            "0               0.641253\n",
            "1               0.618788\n",
            "2               0.633084\n",
            "3               0.651464\n",
            "4               0.638530\n",
            "5               0.631042\n",
            "6               0.639891\n",
            "7               0.653506\n",
            "8               0.632403\n",
            "9               0.625596\n",
            "\n",
            " The average accuracy is : 0.6365554799183119\n",
            "\n",
            " The standard deviation is : 0.010760737115253691\n",
            "\n",
            " Testing with partitions and depth = 3 \n",
            "\n",
            "   Accuracy of partition\n",
            "0               0.646018\n",
            "1               0.626957\n",
            "2               0.633084\n",
            "3               0.651464\n",
            "4               0.645337\n",
            "5               0.634445\n",
            "6               0.639891\n",
            "7               0.658952\n",
            "8               0.632403\n",
            "9               0.629680\n",
            "\n",
            " The average accuracy is : 0.6398230088495576\n",
            "\n",
            " The standard deviation is : 0.01037088394750886\n",
            "\n",
            " GENERATING RANDOM FOREST \n",
            "\n",
            "Accuracy of the random forest is: 0.6554965263588067\n",
            "\n",
            "***** EVALUATING RANDOM FOREST ******\n",
            "\n",
            "\n",
            " GENERATING RANDOM FOREST OF 3 CARTS - 10 RUNS \n",
            "\n",
            "Accuracys of 10 runs with random forest of 3 CARTS \n",
            "    Accuracy of run\n",
            "0         0.652432\n",
            "1         0.651206\n",
            "2         0.653249\n",
            "3         0.647528\n",
            "4         0.643237\n",
            "5         0.652023\n",
            "6         0.642011\n",
            "7         0.653862\n",
            "8         0.648141\n",
            "9         0.647732\n",
            "\n",
            " The average accuracy is : 0.6491418062934204\n",
            "\n",
            " The standard deviation is : 0.004134544147343059\n",
            "\n",
            " GENERATING RANDOM FOREST OF 5 CARTS - 10 RUNS \n",
            "\n",
            "Accuracys of 10 runs with random forest of 5 CARTS \n",
            "    Accuracy of run\n",
            "0         0.656110\n",
            "1         0.648549\n",
            "2         0.653453\n",
            "3         0.653862\n",
            "4         0.647936\n",
            "5         0.653862\n",
            "6         0.653862\n",
            "7         0.656723\n",
            "8         0.653862\n",
            "9         0.656110\n",
            "\n",
            " The average accuracy is : 0.653432774826318\n",
            "\n",
            " The standard deviation is : 0.0029804911035147363\n"
          ]
        }
      ],
      "source": [
        "class Node_CART:    \n",
        "    def __init__(self, num_classes = 4, ref_CART = None, current_depth = 0):\n",
        "        \"\"\"\n",
        "        Create the node attributes\n",
        "        param num_classes: K number of classes to classify\n",
        "        param ref_cart: reference to the tree containing the node\n",
        "        param current_depth: current depth of the node in the tree\n",
        "        \"\"\"\n",
        "        self.ref_CART = ref_CART\n",
        "        self.threshold_value = 0\n",
        "        self.feature_num = 0\n",
        "        self.node_right = None\n",
        "        self.node_left = None\n",
        "        self.data_torch_partition = None\n",
        "        self.gini = 0\n",
        "        self.dominant_class = None\n",
        "        self.accuracy_dominant_class = None        \n",
        "        self.num_classes = num_classes\n",
        "        self.current_depth = current_depth\n",
        "    \n",
        "    def to_xml(self, current_str = \"\"):\n",
        "        \"\"\"\n",
        "        Recursive function to write the node content to an xml formatted string\n",
        "        param current_str : the xml content so far in the whole tree\n",
        "        return the string with the node content\n",
        "        \"\"\"\n",
        "        str_node = \"<node><thresh>\" + str(self.threshold_value) + \"</thresh>\" + \"<feature>\" + str(self.feature_num) + \"</feature><depth>\" + str(self.current_depth)+ \"</depth>\" \n",
        "        str_node += \"<gini>\" + str(self.gini) + \"</gini>\"\n",
        "        if(self.node_right != None):\n",
        "            str_left = self.node_right.to_xml(current_str)\n",
        "            str_node += str_left\n",
        "        if(self.node_left != None):\n",
        "            str_right = self.node_left.to_xml(current_str)\n",
        "            str_node += str_right\n",
        "            \n",
        "        if(self.is_leaf()):\n",
        "            str_node += \"<dominant_class>\" + str(self.dominant_class) + \"</dominant_class><acc_dominant_class>\"  + str(self.accuracy_dominant_class) + \"</acc_dominant_class>\"\n",
        "        str_node += \"</node>\"\n",
        "        return str_node\n",
        "    \n",
        "    def is_leaf(self):\n",
        "        \"\"\"\n",
        "        Checks whether the node is a leaf\n",
        "        \"\"\"\n",
        "        return (self.node_left == None and self.node_right == None)\n",
        "    \n",
        "    def create_with_children(self, data_torch, current_depth, list_selected_features = [], min_gini = 0.000001):\n",
        "        \"\"\"\n",
        "        Creates a node by selecting the best feature and threshold, and if needed, creating its children\n",
        "        param data_torch: dataset with the current partition to deal with in the node\n",
        "        param current_depth: depth counter for the node\n",
        "        param list_selected_features: list of selected features so far for the CART building process\n",
        "        param min_gini: hyperparmeter selected by the user defining the minimum tolerated gini coefficient for a  node\n",
        "        return the list of selected features so far\n",
        "        \"\"\"        \n",
        "        #update depth of children\n",
        "        depth_children = current_depth + 1\n",
        "        if(depth_children <= self.ref_CART.get_max_depth()):\n",
        "            num_observations = data_torch.shape[0]            \n",
        "            #careful with max depth\n",
        "            #if no threshold and feature were selected, select it using a greedy approach            \n",
        "            (threshold_value, feature_num, gini) = self.select_best_feature_and_thresh(data_torch, list_features_selected = list_selected_features)\n",
        "            list_selected_features += [feature_num]\n",
        "            #store important data in attributes\n",
        "            self.threshold_value = threshold_value\n",
        "            self.feature_num = feature_num\n",
        "            self.data_torch_partition = data_torch\n",
        "            self.gini = gini            \n",
        "            num_features = data_torch.shape[1]\n",
        "            #data_torch_left = torch.zeros(1, num_features)\n",
        "            #data_torch_right = torch.zeros(1, num_features)\n",
        "            #create the right and left node data if the current gini is still high            \n",
        "            if(self.gini > min_gini):\n",
        "                data_torch_left = data_torch[data_torch[:, feature_num] < threshold_value]\n",
        "                data_torch_right = data_torch[data_torch[:, feature_num] >= threshold_value]\n",
        "                #if the new partitions have more than min_observations, make them\n",
        "                if(data_torch_left.shape[0] >= self.ref_CART.get_min_observations() and data_torch_right.shape[0] >= self.ref_CART.get_min_observations()):\n",
        "                    #add data to the right and left children\n",
        "                    self.node_right = Node_CART(num_classes = self.num_classes, ref_CART = self.ref_CART, current_depth = depth_children)\n",
        "                    self.node_left = Node_CART(num_classes = self.num_classes, ref_CART = self.ref_CART, current_depth = depth_children)\n",
        "                    list_selected_features = self.node_right.create_with_children(data_torch_right, depth_children, list_selected_features = list_selected_features)            \n",
        "                    self.node_left.create_with_children( data_torch_left, depth_children, list_selected_features = list_selected_features)\n",
        "        #if is leaf, fill the         \n",
        "        if(self.is_leaf()):\n",
        "            labels_data = data_torch[:, -1]\n",
        "            self.dominant_class = torch.mode(labels_data).values.item()\n",
        "            num_obs_label = labels_data[labels_data == self.dominant_class].shape[0]\n",
        "            self.accuracy_dominant_class = num_obs_label / labels_data.shape[0]           \n",
        "            \n",
        "        return list_selected_features\n",
        "    \n",
        "    \n",
        "    def select_best_feature_and_thresh(self, data_torch, list_features_selected = [], num_classes = 4):\n",
        "        \"\"\"\n",
        "        ONLY USE  2 FORS\n",
        "        Selects the best feature and threshold that minimizes the gini coefficient\n",
        "        param data_torch: dataset partition to analyze\n",
        "        param list_features_selected list of features selected so far, thus must be ignored \n",
        "        param num_classes: number of K classes to discriminate from \n",
        "        return min_thresh, min_feature, min_gini found for the dataset partition when \n",
        "        selecting the found feature and threshold\n",
        "        \"\"\"       \n",
        "        min_thresh = 0\n",
        "        min_feature = ''\n",
        "        min_gini = 1\n",
        "        \n",
        "        for feature_num in range(num_classes):\n",
        "            for tresh in data_torch[:, feature_num].unique():\n",
        "                data_torch_left = data_torch[data_torch[:, feature_num] < tresh]\n",
        "                data_torch_right = data_torch[data_torch[:, feature_num] >= tresh]\n",
        "                \n",
        "                left_classes, right_classes = data_torch_left[:, -1], data_torch_right[:, -1] \n",
        "                \n",
        "                gini_left = self.calculate_gini(left_classes, num_classes)\n",
        "                gini_right = self.calculate_gini(right_classes, num_classes)\n",
        "                gini_ponderado = ((data_torch_left.shape[0] / data_torch.shape[0]) * gini_left) + ((data_torch_right.shape[0] / data_torch.shape[0]) * gini_right)\n",
        "                \n",
        "                if gini_ponderado < min_gini:\n",
        "                    min_gini = gini_ponderado\n",
        "                    min_feature = feature_num\n",
        "                    min_thresh = tresh.item()\n",
        "                \n",
        "            \n",
        "        return (min_thresh, min_feature, min_gini)   \n",
        "        \n",
        "    \n",
        "    def calculate_gini(self, data_partition_torch, num_classes = 4):\n",
        "        \"\"\"\n",
        "        Calculates the gini coefficient for a given partition with the given number of classes\n",
        "        param data_partition_torch: current dataset partition as a tensor\n",
        "        param num_classes: K number of classes to discriminate from\n",
        "        returns the calculated gini coefficient\n",
        "        \"\"\"\n",
        "        uniq, counts = data_partition_torch.unique(return_counts=True)\n",
        "        totalQty = data_partition_torch.shape[0]\n",
        "        gini = 1 - sum( (counts / totalQty)  **2)\n",
        "        return gini\n",
        "   \n",
        "    \n",
        "    def evaluate_node(self, input_torch): \n",
        "        \"\"\"\n",
        "        Evaluates an input observation within the node. \n",
        "        If is not a leaf node, send it to the corresponding node\n",
        "        return predicted label\n",
        "        \"\"\"\n",
        "        feature_val_input = input_torch[self.feature_num]\n",
        "        if(self.is_leaf()):\n",
        "            return self.dominant_class\n",
        "        else:\n",
        "            if(feature_val_input < self.threshold_value):\n",
        "                return self.node_left.evaluate_node(input_torch)\n",
        "            else:\n",
        "                return self.node_right.evaluate_node(input_torch)\n",
        "        \n",
        "\n",
        "class CART:\n",
        "    def __init__(self, dataset_torch, max_CART_depth = 4, min_observations = 2):\n",
        "        \"\"\"\n",
        "        CART has only one root node\n",
        "        \"\"\"\n",
        "        #min observations per node\n",
        "        self.min_observations = min_observations\n",
        "        self.root = Node_CART(num_classes = 4, ref_CART = self, current_depth = 0)\n",
        "        self.max_CART_depth = max_CART_depth\n",
        "        self.list_selected_features = []\n",
        "        \n",
        "    def get_root(self):\n",
        "        \"\"\"\n",
        "        Gets tree root\n",
        "        \"\"\"\n",
        "        return self.root\n",
        "    \n",
        "    def get_min_observations(self):\n",
        "        \"\"\"\n",
        "        return min observations per node\n",
        "        \"\"\"\n",
        "        return self.min_observations\n",
        "    \n",
        "    def get_max_depth(self):\n",
        "        \"\"\"\n",
        "        Gets the selected max depth of the tree\n",
        "        \"\"\"\n",
        "        return self.max_CART_depth\n",
        "    \n",
        "    def build_CART(self, data_torch):\n",
        "        \"\"\"\n",
        "        Build CART from root\n",
        "        \"\"\"\n",
        "        self.list_selected_features = self.root.create_with_children(data_torch, current_depth = 0)\n",
        "    \n",
        "    def to_xml(self, xml_file_name):\n",
        "        \"\"\"\n",
        "        write Xml file with tree content\n",
        "        \"\"\"\n",
        "        str_nodes = self.root.to_xml()\n",
        "        file = open(xml_file_name,\"w+\") \n",
        "        file.write(str_nodes)\n",
        "        file.close()\n",
        "        return str_nodes\n",
        "    \n",
        "    \n",
        "    def evaluate_input(self, input_torch):\n",
        "        \"\"\"\n",
        "        Evaluate a specific input in the tree and get the predicted class\n",
        "        \"\"\"\n",
        "        return self.root.evaluate_node(input_torch)\n",
        "        \n",
        "    \n",
        "def train_CART(dataset_torch, name_xml = \"\", max_CART_depth = 3, min_obs_per_leaf = 2): \n",
        "    \"\"\"\n",
        "    Train CART model\n",
        "    \"\"\"\n",
        "    tree = CART(dataset_torch = dataset_torch, max_CART_depth = max_CART_depth, min_observations =  min_obs_per_leaf)\n",
        "    tree.build_CART(dataset_torch)\n",
        "    if(not name_xml == \"\"):\n",
        "        tree.to_xml(name_xml)\n",
        "    return tree\n",
        "\n",
        "def test_CART(tree, testset_torch):\n",
        "    \"\"\"\n",
        "    Test a previously built CART\n",
        "    \"\"\"\n",
        "    correct_observations = 0\n",
        "    for observation in testset_torch:\n",
        "        predicted = tree.evaluate_input(observation)\n",
        "        classy = observation[-1].item()\n",
        "        if predicted == classy:\n",
        "            correct_observations += 1 \n",
        "    return correct_observations / testset_torch.shape[0]\n",
        "\n",
        "def partition_validation(dataset_torch, max_CART_depth, num_splits):\n",
        "    rs = ShuffleSplit(n_splits=num_splits, train_size=0.7, test_size=0.3, random_state=0)\n",
        "    accuracys = []\n",
        "    for train_index, test_index in rs.split(dataset_torch):\n",
        "        treex = train_CART(dataset_torch[train_index], name_xml = \"CART_depth_partitions.xml\", max_CART_depth = max_CART_depth)\n",
        "        accx = test_CART(treex, dataset_torch[test_index])\n",
        "        accuracys.append([accx])\n",
        "    return accuracys\n",
        "        \n",
        "        \n",
        "class Random_Forest:\n",
        "    \"\"\"\n",
        "    Creates the random forest\n",
        "    param num_trees: K number of trees that will be generated\n",
        "    param original_data: original dataset\n",
        "    param random_data_subsets: list of random subsets that will be used in the different CARTs\n",
        "    param list_of_carts: list of CARTs\n",
        "    param depth_of_trees: depth of all the tree in the random forest\n",
        "    \"\"\"\n",
        "    def __init__(self, original_data = None, num_trees = 0, depth_of_trees = 2):\n",
        "        self.original_data = original_data\n",
        "        self.num_trees = num_trees\n",
        "        self.random_data_subsets = []\n",
        "        self.list_of_carts = []\n",
        "        self.depth_of_trees = depth_of_trees\n",
        "    \n",
        "        \n",
        "    def num_trees(self):\n",
        "        \"\"\"\n",
        "        Gets the num of CARTs\n",
        "        \"\"\"\n",
        "        return self.num_trees\n",
        "    \n",
        "    def get_original_data(self):\n",
        "        \"\"\"\n",
        "        Gets the original dataset\n",
        "        \"\"\"\n",
        "        return self.original_data\n",
        "    \n",
        "    def get_random_data_subsets(self):\n",
        "        \"\"\"\n",
        "        Gets a list of the random subsets that will generate the CARTs\n",
        "        \"\"\"\n",
        "        return self.max_CART_depth\n",
        "    \n",
        "    def get_list_of_carts(self):\n",
        "        \"\"\"\n",
        "        Gets a list of the random subsets that will generate the CARTs\n",
        "        \"\"\"\n",
        "        return self.list_of_carts\n",
        "    \n",
        "    def get_depth_of_trees(self):\n",
        "        \"\"\"\n",
        "        Gets a list of the random subsets that will generate the CARTs\n",
        "        \"\"\"\n",
        "        return self.depth_of_trees\n",
        "    \n",
        "    def generate_random_forest(self, partitions):\n",
        "        for train_index, test_index in partitions.split(self.original_data):\n",
        "            self.random_data_subsets.append(self.original_data[train_index])\n",
        "        idx = 0\n",
        "        for data_subset in self.random_data_subsets:\n",
        "            treex = train_CART(data_subset, \"Forest_CART\" + str(idx) + \".xml\", self.depth_of_trees, 2)\n",
        "            self.list_of_carts.append(treex)\n",
        "            idx += 1\n",
        "            \n",
        "    def evaluate_random_forest(self, input_torch):\n",
        "        predicted_categories = []\n",
        "        for cart in self.list_of_carts:\n",
        "            predicted_categories.append(cart.evaluate_input(input_torch))\n",
        "        #Returns the most common element from the prediction of all trees\n",
        "        return max(set(predicted_categories), key=predicted_categories.count)\n",
        "        \n",
        "    def test_random_forest(self, testset_torch):\n",
        "        correct_observations = 0\n",
        "        for observation in testset_torch:\n",
        "            predicted = self.evaluate_random_forest(observation)\n",
        "            classy = observation[-1].item()\n",
        "            if predicted == classy:\n",
        "                correct_observations += 1\n",
        "        return correct_observations / testset_torch.shape[0]\n",
        "            \n",
        "\n",
        "def train_random_forest(testset_torch, k_partitions, depth_per_tree):\n",
        "    forest = Random_Forest(testset_torch, k_partitions, depth_per_tree)\n",
        "    kf = KFold(n_splits=k_partitions, shuffle=True)\n",
        "    forest.generate_random_forest(kf)\n",
        "    return forest\n",
        "\n",
        "\n",
        "dataset_torch = read_dataset(csv_name=\"/content/drive/MyDrive/Colab Notebooks/P1/sao-paulo-properties-april-2019.csv\")\n",
        "\n",
        "dataset_torch = torch.tensor(dataset_torch.values)\n",
        "\n",
        "#### EVALUACION DEL CART\n",
        "\n",
        "tree2 = train_CART(dataset_torch, name_xml = \"CART_depth_2.xml\", max_CART_depth = 2)\n",
        "acc2 = test_CART(tree2, dataset_torch)\n",
        "print(\"The accuracy for depth 2 is of: \", acc2, \"\\n\")\n",
        "\n",
        "tree3 = train_CART(dataset_torch, name_xml = \"CART_depth_3.xml\", max_CART_depth = 3)\n",
        "acc3 = test_CART(tree3, dataset_torch)\n",
        "print(\"The accuracy for depth 3 is of: \", acc3, \"\\n\")\n",
        "\n",
        "### PARTICIONES\n",
        "\n",
        "print(\"************** Testing with partitions **************** \\n\")\n",
        "\n",
        "print(\"Testing with partitions and depth = 2 \\n\")\n",
        "\n",
        "accuracys = partition_validation(dataset_torch, 2, 10)\n",
        "accurracy_df = pandas.DataFrame(accuracys, columns = ['Accuracy of partition'])\n",
        "print(accurracy_df)\n",
        "print(\"\\n The average accuracy is :\", accurracy_df['Accuracy of partition'].mean())\n",
        "print(\"\\n The standard deviation is :\", accurracy_df['Accuracy of partition'].std())\n",
        "\n",
        "\n",
        "print(\"\\n Testing with partitions and depth = 3 \\n\")\n",
        "\n",
        "accuracys = partition_validation(dataset_torch, 3, 10)\n",
        "accurracy_df = pandas.DataFrame(accuracys, columns = ['Accuracy of partition'])\n",
        "print(accurracy_df)\n",
        "print(\"\\n The average accuracy is :\", accurracy_df['Accuracy of partition'].mean())\n",
        "print(\"\\n The standard deviation is :\", accurracy_df['Accuracy of partition'].std())\n",
        "\n",
        "#RANDOM FOREST\n",
        "\n",
        "print(\"\\n GENERATING RANDOM FOREST \\n\")\n",
        "\n",
        "rf_model = train_random_forest(dataset_torch, 5, 3)\n",
        "forest_acc = rf_model.test_random_forest(dataset_torch)\n",
        "\n",
        "print(\"Accuracy of the random forest is:\", forest_acc)\n",
        "\n",
        "print(\"\\n***** EVALUATING RANDOM FOREST ******\\n\")\n",
        "\n",
        "accuracys = []\n",
        "print(\"\\n GENERATING RANDOM FOREST OF 3 CARTS - 10 RUNS \\n\")\n",
        "for i in range(10):\n",
        "    rf_model = train_random_forest(dataset_torch, 3, 3)\n",
        "    forest_acc = rf_model.test_random_forest(dataset_torch)\n",
        "    accuracys.append([forest_acc])\n",
        "forest_accurracy_df = pandas.DataFrame(accuracys, columns = ['Accuracy of run'])\n",
        "print(\"Accuracys of 10 runs with random forest of 3 CARTS \\n\", forest_accurracy_df)\n",
        "print(\"\\n The average accuracy is :\", forest_accurracy_df['Accuracy of run'].mean())\n",
        "print(\"\\n The standard deviation is :\", forest_accurracy_df['Accuracy of run'].std())\n",
        "\n",
        "print(\"\\n GENERATING RANDOM FOREST OF 5 CARTS - 10 RUNS \\n\")\n",
        "\n",
        "accuracys = []\n",
        "for i in range(10):\n",
        "    rf_model = train_random_forest(dataset_torch, 5, 3)\n",
        "    forest_acc = rf_model.test_random_forest(dataset_torch)\n",
        "    accuracys.append([forest_acc])\n",
        "forest_accurracy_df = pandas.DataFrame(accuracys, columns = ['Accuracy of run'])\n",
        "print(\"Accuracys of 10 runs with random forest of 5 CARTS \\n\", forest_accurracy_df)\n",
        "print(\"\\n The average accuracy is :\", forest_accurracy_df['Accuracy of run'].mean())\n",
        "print(\"\\n The standard deviation is :\", forest_accurracy_df['Accuracy of run'].std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq-vUOaNZNbY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "P1DecisionTrees.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}